{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:06:36.990619400Z",
     "start_time": "2024-04-15T19:06:35.412758Z"
    }
   },
   "outputs": [],
   "source": [
    "import time, json, re\n",
    "from urllib.parse import unquote\n",
    "from tqdm import tqdm\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver import ActionChains\n",
    "\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3071830bf0301a",
   "metadata": {},
   "source": [
    "# Utility functions\n",
    "Functions used to extract the property attributes when scraping the property webpage\n",
    "### Extract price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b650f86660bd0892",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:06:37.013607300Z",
     "start_time": "2024-04-15T19:06:36.995582700Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_price(browser):\n",
    "    # Extract the price per night\n",
    "    try:\n",
    "        # If no discount\n",
    "        return float(browser.find_element(By.XPATH, \"//*[@class='_tyxjp1']\").get_attribute('innerHTML').split(';')[1].split('&')[0])\n",
    "    except:\n",
    "        try:\n",
    "            # If discount\n",
    "            return float(browser.find_element(By.XPATH, \"//*[@class='_1y74zjx']\").get_attribute('innerHTML').split(';')[1].split('&')[0])\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52f1f263a423910",
   "metadata": {},
   "source": [
    "### Extract details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dfb9a8002626206",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:06:37.059633200Z",
     "start_time": "2024-04-15T19:06:37.009580200Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_details(browser):\n",
    "    # Extract the property details\n",
    "    \n",
    "    # Property detail keywords\n",
    "    keywords = {\n",
    "        'guest': 'guests', 'guests': 'guests',\n",
    "        'bedroom': 'bedrooms', 'bedrooms': 'bedrooms',\n",
    "        'bed': 'beds', 'beds': 'beds',\n",
    "        'bath': 'baths', 'baths': 'baths'\n",
    "    }\n",
    "    \n",
    "    details = {'guests': None, 'beds': None, 'bedrooms': None, 'baths': None}  # Default to null if not found\n",
    "    details_ol = browser.find_elements(By.XPATH, '//div[contains(@class, \"o1kjrihn\")]//ol/li')  # Attempt to locate the details list\n",
    "\n",
    "    # Find and extract each unique property detail\n",
    "    for detail_li in details_ol:\n",
    "        text = detail_li.get_attribute('innerText').strip()\n",
    "        for keyword in keywords:\n",
    "            if keyword in text:\n",
    "                match = re.search(r'\\d+', text)\n",
    "                if match:\n",
    "                    number = int(match.group())\n",
    "                    detail_key = keywords[keyword]\n",
    "                    details[detail_key] = number\n",
    "                break  # Found the number, no need to continue with other keywords\n",
    "    return details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c7869164387f5",
   "metadata": {},
   "source": [
    "### Extract superhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5f42a53f1ed97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:06:37.088596800Z",
     "start_time": "2024-04-15T19:06:37.047581300Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_superhost(browser):\n",
    "    # Extract if Superhost\n",
    "    try:\n",
    "        elem = browser.find_element(By.XPATH, \"//div[@class='s1l7gi0l atm_c8_km0zk7 atm_g3_18khvle atm_fr_1m9t47k atm_7l_1esdqks dir dir-ltr']\")\n",
    "        elems = elem.find_elements(By.XPATH, \"//li[@class='l7n4lsf atm_9s_1o8liyq_keqd55 dir dir-ltr']\")\n",
    "        for el in elems:\n",
    "            if el.text == \"Superhost\":\n",
    "                return True\n",
    "        return False\n",
    "    except:\n",
    "        return False  # Default to false if not found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c24469214fb02cd",
   "metadata": {},
   "source": [
    "### Extract guest favorite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a20a67e32a5ffbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:06:37.121596400Z",
     "start_time": "2024-04-15T19:06:37.076581800Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_guest_favorite(browser):\n",
    "    # Extract if Guest Favorite\n",
    "    try:\n",
    "        elem = browser.find_element(By.XPATH, \"//div[contains(text(), 'Guest favorite')]\")\n",
    "        return elem.text == \"Guest favorite\"  # Return True if the element exists and has the expected text      \n",
    "    except:\n",
    "       return False  # Default to false if not found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbaf5cfdcff1b7a",
   "metadata": {},
   "source": [
    "### Extract review index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac0d47d9f640c2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:06:37.124580100Z",
     "start_time": "2024-04-15T19:06:37.096580200Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_review_index_number_reviews(browser):\n",
    "    # Extract the review index and the number of reviews\n",
    "    review_index, number_reviews = None, None\n",
    "    \n",
    "    # Attempt to find the review index\n",
    "    try: \n",
    "        elem = browser.find_element(By.XPATH, \"//*[contains(text(), 'Rated')]\")\n",
    "        full_text = elem.get_attribute(\"innerHTML\") # Get the full text\n",
    "        numbers = re.findall(r\"\\d+,\\d+|\\d+\\.\\d+|\\d+\", full_text)\n",
    "        review_index = float(numbers[0].replace(',', '.'))   # Extract the first number from this text            \n",
    "    except NoSuchElementException:\n",
    "        review_index = None  # Default to null if not found\n",
    "            \n",
    "    # Attempt to find the number of reviews                   \n",
    "    try:    \n",
    "        number_reviews_elem = browser.find_elements(By.XPATH, \"//*[contains(text(), 'reviews')]\")\n",
    "        for elem in number_reviews_elem:\n",
    "            if re.search(r'\\d+', elem.text):\n",
    "                number_reviews = int(re.search(r'\\d+', elem.text).group())\n",
    "                break\n",
    "        if number_reviews is None: \n",
    "            number_reviews = None\n",
    "    except NoSuchElementException:\n",
    "        number_reviews = None  # Default to null if not found\n",
    "                \n",
    "    return review_index, number_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1eb8188a39c4f",
   "metadata": {},
   "source": [
    "### Extract host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb553087b134078",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:06:37.240579900Z",
     "start_time": "2024-04-15T19:06:37.135586700Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_host(browser):\n",
    "    # Extract the property host\n",
    "    try:\n",
    "        # Search for elements that contain \"Hosted by\"\n",
    "        elem = browser.find_element(By.XPATH, \"//*[contains(text(), 'Hosted by')]\")\n",
    "        # Use regex to split the text by \"Hosted by \" and capture the following text\n",
    "        host_name_match = re.search(r'(?:Hosted by)(.+)', elem.text)\n",
    "        if host_name_match: # If the regex finds a match, return the captured group which is the host's name\n",
    "            return host_name_match.group(1)\n",
    "    except NoSuchElementException:\n",
    "        return None  # Default to null if not found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d672a73baee65",
   "metadata": {},
   "source": [
    "### Extract characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "489f0a7b6bf72cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:06:37.242579200Z",
     "start_time": "2024-04-15T19:06:37.158594600Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_characteristics(browser):\n",
    "    # Extract the property characteristics\n",
    "    try:\n",
    "        characteristics = []\n",
    "        elems = browser.find_elements(By.XPATH, \"//div[@class='_sg8691']\")\n",
    "        for elem in elems:\n",
    "            characteristics.append(elem.text)\n",
    "        return characteristics\n",
    "    except:\n",
    "        return []  # Default to empty list if not found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e46062d56b3b66d",
   "metadata": {},
   "source": [
    "### Extract coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c845923b69cafceb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:06:37.243589Z",
     "start_time": "2024-04-15T19:06:37.170579900Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_coordinates(browser):\n",
    "    # Extract the property coordinates\n",
    "    coordinates = dict()\n",
    "    \n",
    "    try:\n",
    "        # Scroll to the middle of the page in order to load the Google map\n",
    "        footer = browser.find_element(By.XPATH, \"//*[@class='ff6a337 atm_26_116dmco atm_67_1vlbu9m dir dir-ltr']\")\n",
    "        delta_y = footer.rect['y']\n",
    "        ActionChains(browser).scroll_by_amount(0, int(delta_y * 0.65)).perform()\n",
    "    except:\n",
    "        return coordinates  # Default to empty dict if not found\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Gets all the logs from performance in Chrome\n",
    "    logs = browser.get_log(\"performance\")\n",
    "    \n",
    "    # Iterate the network logs to find the map location query request\n",
    "    for log in logs:\n",
    "        network_log = json.loads(log[\"message\"])[\"message\"]\n",
    "    \n",
    "        if (\"Network.response\" in network_log[\"method\"]\n",
    "                or \"Network.request\" in network_log[\"method\"]\n",
    "                or \"Network.webSocket\" in network_log[\"method\"]):\n",
    "    \n",
    "            try:\n",
    "                url = network_log[\"params\"][\"request\"][\"url\"]\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "            if \"MapViewportInfoQuery\" in url:\n",
    "                try:\n",
    "                    loc = url.split(\"&\")\n",
    "                    loc = loc[len(loc) - 2]\n",
    "                    loc = loc.split(\"=\")[1]\n",
    "        \n",
    "                    json_loc = json.loads(unquote(loc))\n",
    "                    \n",
    "                    coordinates[\"lat\"] = float((json_loc['request']['boundingBox']['southwest']['lat'] + json_loc['request']['boundingBox']['northeast']['lat']) / 2)\n",
    "                    coordinates[\"lng\"] = float((json_loc['request']['boundingBox']['southwest']['lng'] + json_loc['request']['boundingBox']['northeast']['lng']) / 2)\n",
    "        \n",
    "                    break\n",
    "                except:\n",
    "                    return coordinates  # Default to empty dict if not found\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a172eb5-4f15-46b8-9e9d-8351dea1d400",
   "metadata": {},
   "source": [
    "### Accept cookies on page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39c6fdc7-65ad-441c-8c17-980119df6d3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:06:37.270582100Z",
     "start_time": "2024-04-15T19:06:37.213579200Z"
    }
   },
   "outputs": [],
   "source": [
    "def accept_cookies():\n",
    "    # Accept cookies\n",
    "    try:\n",
    "        # Wait for the cookie button to be clickable\n",
    "        cookie_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'OK')]\")))\n",
    "        cookie_button.click()\n",
    "    except:\n",
    "        pass  # If the cookie button is not visible after 5 seconds, we can assume it didn't appear (or it was already closed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff457d1cc6c90119",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create the property object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17a51e50e84767ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:06:37.336579400Z",
     "start_time": "2024-04-15T19:06:37.230581300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_db_object(browser, region):\n",
    "    # Create the property object\n",
    "    \n",
    "    # Instantiate a dictionary to store the property attributes\n",
    "    db_object = dict()\n",
    "    \n",
    "    # Extract the price\n",
    "    price = extract_price(browser)\n",
    "    db_object['price'] = price\n",
    "    \n",
    "    # Extract the property details\n",
    "    details = extract_details(browser)\n",
    "    db_object['details'] = details\n",
    "    \n",
    "    # Extract the superhost status\n",
    "    superhost = extract_superhost(browser)\n",
    "    db_object['superhost'] = superhost\n",
    "    \n",
    "    # Extract the guest favorite status\n",
    "    guest_favorite = extract_guest_favorite(browser)\n",
    "    db_object['guest_favorite'] = guest_favorite\n",
    "    \n",
    "    # Extract the review index and number of reviews\n",
    "    review_index, number_reviews = extract_review_index_number_reviews(browser)\n",
    "    db_object['review_index'] = review_index\n",
    "    db_object['number_reviews'] = number_reviews\n",
    "     \n",
    "    # Extract the host name\n",
    "    host = extract_host(browser)\n",
    "    db_object['host'] = host\n",
    "    \n",
    "    # Extract the property characteristics\n",
    "    characteristics = extract_characteristics(browser) \n",
    "    db_object['characteristics'] = characteristics\n",
    "    \n",
    "    # Extract the coordinates\n",
    "    coordinates = extract_coordinates(browser)\n",
    "    if len(coordinates) != 0:\n",
    "        db_object['location'] = {\n",
    "            'type': \"Point\",\n",
    "            'coordinates': [coordinates['lat'], coordinates['lng']]\n",
    "        }\n",
    "    \n",
    "    # Set the property region\n",
    "    db_object['region'] = region\n",
    "    \n",
    "    return db_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af282ef7ed71071d",
   "metadata": {},
   "source": [
    "# Airbnb scraping process\n",
    "The process of accessing the Airbnb website and scraping information about properties\n",
    "### Initiate the browser driver and access the Airbnb website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187393ebcdad4b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the webdriver object and set the options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.set_capability(\"goog:loggingPrefs\", {\"performance\": \"ALL\"})\n",
    "options.add_argument(\"--start-maximized\")\n",
    "\n",
    "browser = webdriver.Chrome(options=options)\n",
    "\n",
    "browser.get('https://www.airbnb.com/')\n",
    "\n",
    "# Set a driver wait which will wait for max 5 seconds when called\n",
    "wait = WebDriverWait(browser, 5)\n",
    "accept_cookies()\n",
    "\n",
    "# Keep the original window of the browser for future redirects to new tabs\n",
    "original_window = browser.current_window_handle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ce89beb1dd6dd1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Setup MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f0f3f5ff0b92f99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:06:52.706713600Z",
     "start_time": "2024-04-15T19:06:52.135162800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MongoDB info\n",
    "mongo_host = \"\"\n",
    "mongo_port = 0\n",
    "mongo_database = \"\"\n",
    "mongo_collection = \"\"\n",
    "mongo_username = \"\"\n",
    "mongo_password = \"\"\n",
    "\n",
    "# Connect to MongoDB\n",
    "client = pymongo.MongoClient(mongo_host, mongo_port, username=mongo_username, password=mongo_password)\n",
    "db = client[mongo_database]\n",
    "collection = db[mongo_collection]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42c98ec22b8201",
   "metadata": {},
   "source": [
    "### Navigate to the Thessaloniki (Kalamaria/Panorama/Neapoli-Sikies) properties listing page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c05966dbf743cfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:06:53.433713500Z",
     "start_time": "2024-04-15T19:06:52.712713600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find the location input\n",
    "elem = browser.find_element(By.ID, 'bigsearch-query-location-input')\n",
    "# Search for the region\n",
    "region = 'Kalamaria, Greece'\n",
    "# region = 'Panorama, Greece'\n",
    "# region = 'Neapoli-Sikies, Greece'\n",
    "elem.send_keys(region + Keys.RETURN)\n",
    "\n",
    "# Find and click the search button\n",
    "elem = browser.find_element(By.XPATH, \"//*[@data-testid='structured-search-input-search-button']\")\n",
    "elem.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc997498b2b9a64",
   "metadata": {},
   "source": [
    "### Scrape all properties listed in a page and repeat for multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d020b8e-f962-4fc6-9b0d-d54a33ebab36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T19:46:11.677258900Z",
     "start_time": "2024-04-15T19:06:53.454723400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:05<01:31,  5.39s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:14<02:00,  7.52s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:23<02:00,  8.01s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:31<01:53,  8.13s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:40<01:48,  8.35s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:48<01:41,  8.44s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:57<01:33,  8.54s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:05<01:25,  8.52s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:14<01:17,  8.56s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:23<01:09,  8.63s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:32<01:00,  8.70s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:40<00:52,  8.73s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:49<00:43,  8.74s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [01:58<00:35,  8.81s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:07<00:26,  8.81s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:16<00:17,  8.77s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:24<00:08,  8.72s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:33<00:00,  8.54s/it]\u001b[A\n",
      "  7%|▋         | 1/15 [02:39<37:09, 159.25s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:08<02:24,  8.51s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:17<02:16,  8.53s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:25<02:09,  8.66s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:34<02:01,  8.68s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:43<01:52,  8.66s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:51<01:44,  8.69s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [01:00<01:34,  8.62s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:08<01:25,  8.54s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:17<01:17,  8.60s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:26<01:08,  8.56s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:34<01:00,  8.64s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:43<00:51,  8.64s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:52<00:43,  8.69s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [02:00<00:34,  8.69s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:09<00:25,  8.64s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:18<00:17,  8.62s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:26<00:08,  8.55s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:34<00:00,  8.58s/it]\u001b[A\n",
      " 13%|█▎        | 2/15 [05:18<34:29, 159.21s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:08<02:25,  8.58s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:16<02:13,  8.33s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:24<02:03,  8.26s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:33<01:56,  8.29s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:41<01:48,  8.33s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:49<01:38,  8.24s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:58<01:31,  8.33s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:06<01:23,  8.38s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:15<01:15,  8.35s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:23<01:06,  8.35s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:32<00:59,  8.47s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:40<00:50,  8.34s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:48<00:41,  8.31s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [01:57<00:33,  8.40s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:05<00:25,  8.40s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:13<00:16,  8.41s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:22<00:08,  8.54s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:31<00:00,  8.41s/it]\u001b[A\n",
      " 20%|██        | 3/15 [07:54<31:33, 157.76s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:11<03:14, 11.42s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:23<03:11, 12.00s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:32<02:38, 10.57s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:40<02:15,  9.66s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:49<02:01,  9.32s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:57<01:47,  8.98s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [01:06<01:38,  8.97s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:15<01:28,  8.84s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:24<01:19,  8.78s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:32<01:09,  8.72s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:41<01:01,  8.72s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:50<00:52,  8.74s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:58<00:43,  8.71s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [02:07<00:34,  8.68s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:15<00:25,  8.58s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:24<00:17,  8.54s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:32<00:08,  8.58s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:41<00:00,  8.97s/it]\u001b[A\n",
      " 27%|██▋       | 4/15 [10:40<29:30, 161.00s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:08<02:19,  8.23s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:16<02:14,  8.41s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:25<02:05,  8.34s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:33<01:58,  8.49s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:42<01:51,  8.58s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:51<01:43,  8.63s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [01:00<01:37,  8.87s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:09<01:27,  8.78s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:17<01:19,  8.79s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:26<01:09,  8.66s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:34<00:59,  8.52s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:42<00:50,  8.49s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:51<00:42,  8.50s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [01:59<00:33,  8.44s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:07<00:25,  8.35s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:16<00:16,  8.29s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:24<00:08,  8.36s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:33<00:00,  8.50s/it]\u001b[A\n",
      " 33%|███▎      | 5/15 [13:18<26:38, 159.86s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:07<02:14,  7.94s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:16<02:11,  8.20s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:24<02:03,  8.21s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:32<01:55,  8.26s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:41<01:48,  8.38s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:49<01:40,  8.36s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:58<01:32,  8.41s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:06<01:24,  8.45s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:15<01:15,  8.44s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:23<01:07,  8.46s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:32<00:59,  8.47s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:40<00:51,  8.50s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:48<00:41,  8.39s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [01:57<00:33,  8.37s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:05<00:24,  8.33s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:13<00:16,  8.29s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:22<00:08,  8.38s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:30<00:00,  8.39s/it]\u001b[A\n",
      " 40%|████      | 6/15 [15:53<23:44, 158.30s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:08<02:25,  8.55s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:16<02:14,  8.41s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:24<02:03,  8.25s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:33<01:57,  8.36s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:42<01:50,  8.47s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:50<01:41,  8.44s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:58<01:32,  8.43s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:07<01:24,  8.44s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:15<01:15,  8.44s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:24<01:07,  8.44s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:32<00:59,  8.48s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:41<00:50,  8.50s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:49<00:42,  8.48s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [01:58<00:33,  8.46s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:06<00:25,  8.47s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:15<00:16,  8.44s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:23<00:08,  8.45s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:31<00:00,  8.44s/it]\u001b[A\n",
      " 47%|████▋     | 7/15 [18:29<21:01, 157.70s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:07<02:12,  7.80s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:16<02:10,  8.17s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:24<02:00,  8.03s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:32<01:55,  8.25s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:41<01:48,  8.31s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:49<01:39,  8.26s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:57<01:30,  8.23s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:05<01:22,  8.29s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:13<01:13,  8.22s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:22<01:06,  8.30s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:30<00:58,  8.34s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:38<00:49,  8.24s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:46<00:40,  8.20s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [01:55<00:32,  8.24s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:03<00:24,  8.31s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:11<00:16,  8.23s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:19<00:08,  8.19s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:27<00:00,  8.22s/it]\u001b[A\n",
      " 53%|█████▎    | 8/15 [21:02<18:12, 156.01s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:08<02:19,  8.20s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:16<02:14,  8.40s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:25<02:06,  8.44s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:34<02:03,  8.81s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:43<01:53,  8.72s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:51<01:42,  8.56s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [01:00<01:37,  8.83s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:09<01:27,  8.79s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:17<01:17,  8.65s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:26<01:09,  8.72s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:35<01:00,  8.70s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:44<00:52,  8.73s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:52<00:43,  8.65s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [02:00<00:34,  8.52s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:09<00:25,  8.51s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:17<00:16,  8.44s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:26<00:08,  8.64s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:35<00:00,  8.62s/it]\u001b[A\n",
      " 60%|██████    | 9/15 [23:41<15:42, 157.13s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:08<02:27,  8.68s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:17<02:20,  8.78s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:26<02:11,  8.79s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:34<02:02,  8.74s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:43<01:53,  8.75s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:52<01:43,  8.62s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [01:00<01:34,  8.56s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:09<01:26,  8.69s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:17<01:17,  8.61s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:26<01:09,  8.64s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:35<01:00,  8.58s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:43<00:51,  8.57s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:52<00:43,  8.66s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [02:01<00:34,  8.68s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:09<00:26,  8.67s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:18<00:17,  8.67s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:27<00:08,  8.74s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:35<00:00,  8.66s/it]\u001b[A\n",
      " 67%|██████▋   | 10/15 [26:22<13:11, 158.27s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:08<02:26,  8.61s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:17<02:16,  8.56s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:25<02:07,  8.52s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:33<01:57,  8.42s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:42<01:50,  8.48s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:50<01:41,  8.47s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:59<01:34,  8.62s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:08<01:25,  8.59s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:17<01:17,  8.61s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:25<01:07,  8.42s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:33<00:58,  8.43s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:41<00:50,  8.42s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:50<00:42,  8.47s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [01:58<00:33,  8.49s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:07<00:25,  8.59s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:15<00:16,  8.44s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:24<00:08,  8.44s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:32<00:00,  8.48s/it]\u001b[A\n",
      " 73%|███████▎  | 11/15 [29:00<10:32, 158.03s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:08<02:23,  8.43s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:16<02:12,  8.26s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:25<02:05,  8.35s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:33<01:56,  8.33s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:41<01:47,  8.30s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:50<01:40,  8.37s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:58<01:32,  8.44s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:07<01:24,  8.43s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:15<01:17,  8.56s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:24<01:08,  8.57s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:32<00:59,  8.54s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:41<00:50,  8.49s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:49<00:42,  8.48s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [01:58<00:33,  8.39s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:06<00:24,  8.33s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:15<00:16,  8.50s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:23<00:08,  8.44s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:31<00:00,  8.44s/it]\u001b[A\n",
      " 80%|████████  | 12/15 [31:36<07:52, 157.53s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:07<02:15,  7.97s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:16<02:13,  8.35s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:24<02:04,  8.29s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:33<01:55,  8.26s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:41<01:47,  8.29s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:49<01:40,  8.33s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:58<01:31,  8.35s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:06<01:24,  8.48s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:15<01:16,  8.47s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:24<01:08,  8.56s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:32<00:58,  8.41s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:40<00:50,  8.42s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:48<00:41,  8.28s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [01:56<00:32,  8.25s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:05<00:24,  8.32s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:13<00:16,  8.29s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:21<00:08,  8.23s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:30<00:00,  8.33s/it]\u001b[A\n",
      " 87%|████████▋ | 13/15 [34:11<05:13, 156.59s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:07<02:13,  7.85s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:15<02:07,  7.99s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:23<01:58,  7.91s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:31<01:51,  7.94s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:40<01:46,  8.16s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:48<01:36,  8.08s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:56<01:28,  8.07s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:05<01:23,  8.33s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:13<01:15,  8.34s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:21<01:05,  8.22s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:29<00:58,  8.30s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:37<00:49,  8.22s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:46<00:41,  8.23s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [01:54<00:32,  8.17s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:02<00:24,  8.26s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:11<00:16,  8.30s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:19<00:08,  8.30s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:27<00:00,  8.19s/it]\u001b[A\n",
      " 93%|█████████▎| 14/15 [36:42<02:35, 155.16s/it]\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:08<02:20,  8.29s/it]\u001b[A\n",
      " 11%|█         | 2/18 [00:16<02:11,  8.23s/it]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:24<02:02,  8.17s/it]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:32<01:53,  8.08s/it]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:40<01:44,  8.04s/it]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:48<01:35,  7.99s/it]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:56<01:29,  8.18s/it]\u001b[A\n",
      " 44%|████▍     | 8/18 [01:05<01:23,  8.30s/it]\u001b[A\n",
      " 50%|█████     | 9/18 [01:14<01:15,  8.44s/it]\u001b[A\n",
      " 56%|█████▌    | 10/18 [01:22<01:07,  8.49s/it]\u001b[A\n",
      " 61%|██████    | 11/18 [01:31<00:58,  8.43s/it]\u001b[A\n",
      " 67%|██████▋   | 12/18 [01:39<00:50,  8.48s/it]\u001b[A\n",
      " 72%|███████▏  | 13/18 [01:48<00:42,  8.53s/it]\u001b[A\n",
      " 78%|███████▊  | 14/18 [01:57<00:34,  8.57s/it]\u001b[A\n",
      " 83%|████████▎ | 15/18 [02:05<00:25,  8.60s/it]\u001b[A\n",
      " 89%|████████▉ | 16/18 [02:14<00:17,  8.55s/it]\u001b[A\n",
      " 94%|█████████▍| 17/18 [02:22<00:08,  8.49s/it]\u001b[A\n",
      "100%|██████████| 18/18 [02:30<00:00,  8.38s/it]\u001b[A\n",
      " 93%|█████████▎| 14/15 [39:18<02:48, 168.43s/it]\n"
     ]
    }
   ],
   "source": [
    "db_objects = []\n",
    "num_pages = 15\n",
    "# Iterate through the pages\n",
    "for i in tqdm(range(num_pages)):\n",
    "    # Wait until the page loads\n",
    "    wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//*[@data-testid='card-container']\"))) \n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Find all listed properties specified by the data-testid\n",
    "    elems = browser.find_elements(By.XPATH, \"//*[@data-testid='card-container']\")\n",
    "    \n",
    "    # For every property listed on the page\n",
    "    for j, elem in enumerate(tqdm(elems)):\n",
    "        \n",
    "        # Click on the property\n",
    "        elem.click()\n",
    "        \n",
    "        # Wait until the property is opened in a new tab\n",
    "        wait.until(EC.number_of_windows_to_be(2))\n",
    "        \n",
    "        # Switch the browser to the new tab\n",
    "        for window_handle in browser.window_handles:\n",
    "            if window_handle != original_window:\n",
    "                browser.switch_to.window(window_handle)\n",
    "                break\n",
    "        \n",
    "        # Wait until the property page loads\n",
    "        try:\n",
    "            wait.until(EC.presence_of_element_located((By.XPATH, \"//*[@d='m6 6 20 20M26 6 6 26']\")))\n",
    "            \n",
    "            # Find and click the 'X' for the translation popup\n",
    "            elem = browser.find_element(By.XPATH, \"//*[@d='m6 6 20 20M26 6 6 26']\")\n",
    "            elem.click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Extract the property information\n",
    "        db_object = create_db_object(browser, region)\n",
    "        \n",
    "        # Append to the list of properties\n",
    "        db_objects.append(db_object)\n",
    "        \n",
    "        # Switch the browser to the original listings tab and close the property one\n",
    "        browser.close()\n",
    "        browser.switch_to.window(original_window)\n",
    "      \n",
    "    # Insert all objects to MongoDB\n",
    "    collection.insert_many(db_objects)\n",
    "    db_objects = []\n",
    "    \n",
    "    # Go to the next page  \n",
    "    try:\n",
    "        elem = browser.find_element(By.XPATH, \"//a[@aria-label='Next']\")\n",
    "        elem.click()\n",
    "    except:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
